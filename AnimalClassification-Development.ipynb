{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "#############################################################################################\n",
      "DATASET\n",
      "#############################################################################################\n",
      "\n",
      "\n",
      "\n",
      "                                            Deskripsi       Nama Hewan  \\\n",
      "0   Mempunyai bulu berwarna biru gelap mengilap. B...     Burung Merak   \n",
      "1   Memiliki indra penciuman dan pendengaran yang ...          Beruang   \n",
      "2   Umumnya berbulu burik, kecoklatan atau abu-abu...     Burung Hantu   \n",
      "3   Sanca kembang ini mudah dikenali karena umumny...    Sanca Kembang   \n",
      "4   Komodo merupakan kadal terbesar di dunia, deng...           Komodo   \n",
      "5   Ikan giru atau lebih dikenal dengan sebutan ik...       Ikan Badut   \n",
      "6   Kuda nil memiliki tubuh yang besar dan berat, ...         Kuda Nil   \n",
      "7   Ikan pari manta (Manta birostris) adalah salah...  Ikan Pari Manta   \n",
      "8   Ikan Hiu adalah sekelompok (superordo Selachim...         Ikan Hiu   \n",
      "9   Katak adalah binatang amfibi pemakan serangga ...            Katak   \n",
      "10  Kepiting adalah binatang berkaki sepuluh, yang...         Kepiting   \n",
      "11  Gurita memiliki 8 lengan (bukan tentakel) deng...           Gurita   \n",
      "12  Ikan tuna adalah perenang andal (pernah diukur...        Ikan Tuna   \n",
      "13  Banteng dapat mencapai tinggi sekitar 1,6m di ...          Banteng   \n",
      "\n",
      "     Jenis Hewan  \n",
      "0         Burung  \n",
      "1        Mamalia  \n",
      "2         Burung  \n",
      "3         Reptil  \n",
      "4         Reptil  \n",
      "5           Ikan  \n",
      "6        Mamalia  \n",
      "7           Ikan  \n",
      "8           Ikan  \n",
      "9         Amfibi  \n",
      "10  Invertebrata  \n",
      "11  Invertebrata  \n",
      "12          Ikan  \n",
      "13       Mamalia   \n",
      "\n",
      "DATASET UNIQUE WORDS :\n",
      " ['100', '18', '230', '30', '45', '60', '680', '6m', '77', '810', 'abu', 'ada', 'adalah', 'afrika', 'agak', 'agresif', 'air', 'akan', 'akar', 'aktivitas', 'alam', 'alat', 'amfibi', 'andal', 'aneka', 'anemon', 'arah', 'atas', 'atau', 'atlantik', 'badan', 'badut', 'bagian', 'bahwa', 'bangkong', 'bangsa', 'banteng', 'banyak', 'barat', 'barut', 'bata', 'batu', 'batuan', 'bawah', 'bebas', 'beberapa', 'begitu', 'belakang', 'belakangnya', 'belut', 'bengkok', 'bentuk', 'berada', 'beragam', 'berambut', 'beraneka', 'berasal', 'berat', 'beratnya', 'berbagai', 'berbahaya', 'berbeda', 'berbentuk', 'berbingkul', 'berbintil', 'berbulu', 'bercabang', 'bercagak', 'bercak', 'bercakar', 'berekor', 'berenang', 'berevolusi', 'bergerak', 'bergerigi', 'berjalan', 'berjumlah', 'berkaki', 'berkas', 'berkulit', 'berkurang', 'berlari', 'bernapas', 'berpunuk', 'bersama', 'bersengat', 'bersimbiosis', 'bersisik', 'bertahan', 'bertelinga', 'bertubuh', 'beruang', 'berukuran', 'berupa', 'bervariasi', 'berwarna', 'besar', 'betina', 'betinanya', 'biasa', 'biasanya', 'biji', 'bijian', 'binatang', 'bingkul', 'bintil', 'birostris', 'biru', 'bisa', 'blonde', 'buah', 'bukan', 'bulatan', 'bulu', 'bulunya', 'bundar', 'burik', 'burung', 'cacing', 'cakar', 'cakarnya', 'cambuk', 'cangkang', 'capit', 'cara', 'cekung', 'celah', 'cepat', 'ciri', 'cirrata', 'cm', 'cokelatan', 'coklat', 'corselet', 'cukup', 'cumi', 'dada', 'dadanya', 'dalam', 'dan', 'danau', 'dapat', 'darah', 'darahnya', 'daratan', 'dari', 'daripada', 'dasar', 'daun', 'dedaunan', 'dekat', 'dengan', 'denticles', 'depan', 'deret', 'dermal', 'dewasa', 'di', 'dianggap', 'diatur', 'dibandingkan', 'dibedakan', 'diduga', 'digantikan', 'digunakan', 'dihiasi', 'dikenal', 'dikenali', 'dilapisi', 'dilengkapi', 'dilihat', 'dilindungi', 'dimodifikasi', 'dimorfisme', 'dimulai', 'dinamika', 'dingin', 'dipadukan', 'dipersenjatai', 'diri', 'disebut', 'disekitar', 'diselubungi', 'ditambah', 'ditarik', 'ditekuk', 'ditemukan', 'ditutupi', 'diukur', 'dominan', 'dorsal', 'dorsalnya', 'dua', 'dunia', 'ekor', 'elang', 'empat', 'enam', 'fisik', 'fleksibel', 'fusiform', 'gading', 'garis', 'gelap', 'gemuk', 'gigi', 'giru', 'gunakan', 'gurita', 'hal', 'halnya', 'hampir', 'hanya', 'hari', 'hasil', 'hewan', 'hidup', 'hijau', 'hingga', 'hipural', 'hitam', 'hiu', 'ikan', 'indra', 'ingin', 'ini', 'insang', 'jala', 'jam', 'jambul', 'jantan', 'jantung', 'jarak', 'jarang', 'jari', 'jauh', 'jenis', 'jet', 'jika', 'jingga', 'juga', 'kadal', 'kadang', 'kaki', 'kali', 'kanan', 'kantung', 'karena', 'kasar', 'katak', 'ke', 'kebanyakan', 'kecepatan', 'kecil', 'kecokelat', 'kecokelatan', 'kecoklatan', 'kedua', 'kehijauan', 'kehitaman', 'kelabu', 'kelihatan', 'keluarga', 'kemampuan', 'kembang', 'kemerahan', 'kemungkinan', 'kepala', 'kepalanya', 'kepiting', 'kerangka', 'kerap', 'keras', 'kering', 'kerusakan', 'ketam', 'ketika', 'kg', 'khas', 'kipas', 'kiri', 'kitin', 'km', 'kodok', 'komodo', 'kondisi', 'kontraksi', 'krem', 'kuda', 'kuku', 'kulit', 'kuning', 'kurang', 'laba', 'lain', 'lainnya', 'lapisan', 'laporan', 'lari', 'latar', 'laut', 'lebah', 'lebar', 'lebat', 'lebih', 'lendir', 'lengan', 'lengkap', 'liang', 'licin', 'lidah', 'lima', 'lindungan', 'lingkaran', 'luar', 'makanan', 'makanannya', 'mampu', 'mana', 'mangsa', 'manta', 'mantel', 'manusia', 'masih', 'masing', 'masuk', 'mata', 'matanya', 'melalui', 'melarikan', 'melengkung', 'melewati', 'melihat', 'melindungi', 'melompat', 'memakai', 'memakan', 'memanjat', 'memasukkan', 'mematung', 'membagi', 'membantu', 'membentuk', 'membersihkan', 'membuat', 'membunuh', 'memiliki', 'memipih', 'memiriki', 'memompa', 'mempertahankan', 'mempunyai', 'memungkinkan', 'menaikkan', 'menambah', 'menangkap', 'mencapai', 'mengandung', 'mengarah', 'mengatakan', 'mengeluarkan', 'menggali', 'menggigitnya', 'menggunakan', 'menghadap', 'mengilap', 'mengombakkannya', 'menjadi', 'menjadikan', 'menutup', 'menyebabkan', 'menyelip', 'menyelipkan', 'menyerupai', 'menyobek', 'merah', 'merangkak', 'mereka', 'meruncing', 'merupakan', 'mesin', 'meskipun', 'metalik', 'meter', 'mirip', 'moncong', 'moncongnya', 'moray', 'muda', 'mudah', 'mulut', 'mulutnya', 'naik', 'nama', 'namun', 'nautilus', 'nil', 'olah', 'oleh', 'orang', 'otot', 'ototnya', 'pada', 'pakan', 'paling', 'pandai', 'panjang', 'panjangnya', 'pantai', 'pantat', 'parasit', 'pari', 'paruh', 'pasang', 'pasifik', 'pelat', 'pelindung', 'pemakan', 'pemangsa', 'penciuman', 'pendek', 'pendengaran', 'pengelihatan', 'penghisap', 'penghuni', 'penutup', 'penyokong', 'perairan', 'perenang', 'perilakunya', 'perlahan', 'pernah', 'pertama', 'perut', 'perutnya', 'pipih', 'plankton', 'pohon', 'pola', 'predator', 'pucat', 'pucuk', 'pun', 'pundak', 'pundaknya', 'punggung', 'punuk', 'putih', 'pythonidae', 'ragam', 'rahang', 'rajungan', 'ramping', 'rata', 'rawan', 'rayap', 'relatif', 'rentang', 'reticula', 'ringan', 'rongga', 'ruangan', 'rumput', 'saat', 'saja', 'salah', 'sama', 'sampai', 'samping', 'sanca', 'sangat', 'sarang', 'satu', 'sayapnya', 'sebagai', 'sebenarnya', 'sebuah', 'sebutan', 'secara', 'secepat', 'sedang', 'sedangkan', 'sedikit', 'sefala', 'sehingga', 'sejati', 'sekali', 'sekelompok', 'sekitar', 'seksual', 'selachimorpha', 'selubung', 'seluruh', 'semburan', 'sementara', 'sempit', 'semua', 'sendiri', 'seolah', 'sepanjang', 'sepasang', 'seperti', 'sepuluh', 'serangga', 'sering', 'serta', 'setiap', 'sewaktu', 'siang', 'simetris', 'siphon', 'sirip', 'sisa', 'sisanya', 'sisi', 'sisik', 'sisinya', 'sotong', 'spesies', 'spesiesnya', 'struktur', 'subordo', 'suhu', 'sungai', 'superordo', 'susunan', 'tabung', 'tajam', 'tak', 'tanduk', 'tangan', 'tanpa', 'tawar', 'tebal', 'tegak', 'telah', 'telapak', 'tengah', 'tenggorokannya', 'tengkuk', 'tentakel', 'terbang', 'terbentuk', 'terbesar', 'terbuat', 'tercatat', 'terdapat', 'terdiri', 'tergantung', 'terkecil', 'terkeras', 'terlihat', 'terpanjang', 'terpisah', 'tersebut', 'tersembunyi', 'tersusun', 'terutama', 'thunnus', 'thynnus', 'tiap', 'tidak', 'tidur', 'tiga', 'timur', 'tinggi', 'tipis', 'ton', 'torpedo', 'tubuh', 'tubuhnya', 'tujuh', 'tulang', 'tuna', 'udang', 'ujung', 'ular', 'ulung', 'umum', 'umumnya', 'untuk', 'ventralnya', 'wajah', 'walaupun', 'warna', 'warnanya', 'watak', 'wilayah', 'yakni', 'yang', 'yuyu'] \n",
      "\n",
      "VECTOR DATASET TO ARRAY :\n",
      " [[0.         0.         0.11192295 ... 0.         0.03712323 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.23124171 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.14691454 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.13639473 0.        ]\n",
      " [0.         0.         0.         ... 0.08096292 0.16112541 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.06761725 0.        ]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#############################################################################################\n",
      "SENTENCE INPUT\n",
      "#############################################################################################\n",
      "\n",
      "\n",
      "\n",
      "SENTENCE INPUT :\n",
      " tinggi sekitar 1,6m \n",
      "\n",
      "SENTENCE UNIQUE WORDS :\n",
      " ['6m', 'sekitar', 'tinggi'] \n",
      "\n",
      "VECTOR SENTENCE TO ARRAY :\n",
      " [[0.57735027 0.57735027 0.57735027]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#############################################################################################\n",
      "CALCULATE\n",
      "#############################################################################################\n",
      "\n",
      "\n",
      "\n",
      "VECTORIZE TOKENS :\n",
      " [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#############################################################################################\n",
      "PREDICTION RESULT\n",
      "#############################################################################################\n",
      "\n",
      "\n",
      "\n",
      "PREDICTION :\n",
      " Banteng \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OVERVIEW\n",
    "## TfidfVectorizer(): Convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "## fit_transform(): Learn vocabulary and idf, return term-document matrix.\n",
    "## get_feature_names(): Array mapping from feature integer indices to feature name\n",
    "\n",
    "\n",
    "# IMPORT LIBRARY OR PLUGIN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import find\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "def vectorizeTokens(uniqueTokens, tokens):\n",
    "    vector = []\n",
    "    for token in uniqueTokens:\n",
    "        jumlah = 0\n",
    "        for actualToken in tokens:\n",
    "            if actualToken == token:\n",
    "                jumlah += 1\n",
    "        vector.append(jumlah)\n",
    "    return vector\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "print(\"\\n\\n\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"DATASET\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"\\n\\n\")\n",
    "############################################################################################# \n",
    "\n",
    "\n",
    "# LOAD DATASET FROM CSV\n",
    "csv_data = pd.read_csv('DatasetHewan-Faisal.csv', delimiter = ',')\n",
    "print(csv_data, \"\\n\")\n",
    "\n",
    "# CONVERT DATA CSV as ARRAYS\n",
    "csv_data = np.array(csv_data)\n",
    "\n",
    "# ARRAYS CLASSIFICATION by COLUMN\n",
    "list_desc = []\n",
    "list_anim_name = []\n",
    "list_anim_class = []\n",
    "for index, v in enumerate(csv_data):\n",
    "    ## append(): push data into array\n",
    "    list_desc.append(csv_data[index][0])\n",
    "    list_anim_name.append(csv_data[index][1])\n",
    "    list_anim_class.append(csv_data[index][2])\n",
    "     \n",
    "#print(\"List Animal Desc : \\n\", list_desc, \"\\n\")\n",
    "#print(\"List Animal Name : \\n\", list_anim_name, \"\\n\")\n",
    "#print(\"List Animal Class : \\n\", list_anim_class, \"\\n\")\n",
    "#print(\"\\n---------------------------------\\n\")\n",
    "\n",
    "# CONVERT DATASET INTO TFIDF -> CALCULATE -> COLLECT UNIQUE WORDS\n",
    "vectorizer = TfidfVectorizer()\n",
    "vektor_dataset = vectorizer.fit_transform(list_desc)\n",
    "unique_tokens_dataset = vectorizer.get_feature_names()\n",
    "print(\"DATASET UNIQUE WORDS :\\n\", unique_tokens_dataset, \"\\n\")\n",
    "\n",
    "# CONVERT VECTOR DATASET INTO ARRAY\n",
    "vektor_dataset_to_array = vektor_dataset.toarray()\n",
    "print(\"VECTOR DATASET TO ARRAY :\\n\", vektor_dataset_to_array, \"\\n\")\n",
    "\n",
    "# RESULT BY WORD \n",
    "# for indexArtikel, v in enumerate(list_desc):\n",
    "#     print (\"Article ke\", indexArtikel, \":\", list_desc[indexArtikel])\n",
    "#     for indexKata, kata in enumerate(vectorizer.get_feature_names()):\n",
    "#         print(\"   \", indexKata, \")\", kata, vektor_dataset_to_array[indexArtikel][indexKata])\n",
    "#     print()\n",
    "    \n",
    "\n",
    "#############################################################################################\n",
    "print(\"\\n\\n\")\n",
    "print(\"#############################################################################################\")   \n",
    "print(\"SENTENCE INPUT\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"\\n\\n\")\n",
    "#############################################################################################    \n",
    "   \n",
    "    \n",
    "gnb = GaussianNB()\n",
    "gnb.fit(vektor_dataset_to_array, list_anim_name)\n",
    "    \n",
    "# SENTENCES INPUT\n",
    "sentence = \"tinggi sekitar 1,6m\"\n",
    "print(\"SENTENCE INPUT :\\n\", sentence, \"\\n\")\n",
    "\n",
    "vektor_sentence = vectorizer.fit_transform([sentence])\n",
    "unique_tokens_sentence = vectorizer.get_feature_names();\n",
    "print(\"SENTENCE UNIQUE WORDS :\\n\", unique_tokens_sentence, \"\\n\")\n",
    "\n",
    "# CONVERT VECTOR SENTENCE INTO ARRAY\n",
    "vektor_sentence_to_array = vektor_sentence.toarray()\n",
    "print(\"VECTOR SENTENCE TO ARRAY :\\n\", vektor_sentence_to_array, \"\\n\")\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "print(\"\\n\\n\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"CALCULATE\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"\\n\\n\")\n",
    "############################################################################################# \n",
    "\n",
    "\n",
    "vectorTest = vectorizeTokens(unique_tokens_dataset, unique_tokens_sentence)\n",
    "print(\"VECTORIZE TOKENS :\\n\", [vectorTest], \"\\n\")\n",
    "\n",
    "\n",
    "#############################################################################################\n",
    "print(\"\\n\\n\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"PREDICTION RESULT\")\n",
    "print(\"#############################################################################################\")    \n",
    "print(\"\\n\\n\")\n",
    "############################################################################################# \n",
    "\n",
    "\n",
    "prediction = gnb.predict([vectorTest])\n",
    "print(\"PREDICTION :\\n\", prediction[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
